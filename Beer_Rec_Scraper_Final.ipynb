{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beer Recommender System\n",
    "\n",
    "Notebook 1: Webscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import unicodedata\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1 - Get links for each beer\n",
    "\n",
    "1. Compile dictionaries of beer categories/subcategories\n",
    "2. Create dictionary of beer links per subcategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(link):\n",
    "    \n",
    "    \"\"\" \n",
    "    This function returns a list of websites for each beer in the input, 'link', where \n",
    "    'link' is the website for the 'top 100' beer list webpage. \n",
    "    \n",
    "    INPUT: str (from the above dictionaries - 'dict[key]')\n",
    "    OUTPUT: list\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(link)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, \"lxml\")\n",
    "    table = soup.findAll(\"table\")\n",
    "    data_rows = table[0].findAll('tr')[2:]\n",
    "    # Retrive segment of url link for each specific beer in the \"top\" list\n",
    "    html_sublist=[]\n",
    "    for i in range(len(data_rows)):\n",
    "        link = data_rows[i].find('a')['href']\n",
    "        html_sublist.append(link)\n",
    "    # concatenate first part and second part of url to get to reviews page of each beer\n",
    "    fulllist = ['https://www.beeradvocate.com' + html_sublist[i] +'?view=beer&sort=&start=' for i in range(len(html_sublist))]        \n",
    "    return fulllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_list(dic):\n",
    "    \"\"\"\n",
    "    compiles list of links from dictionary of subcategory of beer type\n",
    "    Input: dictionary\n",
    "    Output: dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    beers_dict = dict()\n",
    "    temp_list = list(dic.keys())\n",
    "    ts = time.time()\n",
    "    \n",
    "    for i in range(len(dic)):\n",
    "        beers_dict[temp_list[i]] = get_list(dic[temp_list[i]]) # call get_list function\n",
    "    \n",
    "    # pickle dictionary\n",
    "    # note: timestamp used for name of each pickled dict\n",
    "    filename = str(ts)+'_dict.pkl'\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(beers_dict, f)\n",
    "        f.close()\n",
    "        \n",
    "    # return object\n",
    "    return beers_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the compile_list function on the following dictionaries to get the url links to each unique beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wheat_beers = {'am_dark_wheat': 'https://www.beeradvocate.com/lists/style/94/',\\\n",
    "               'am_pale_wheat': 'https://www.beeradvocate.com/lists/style/93/',\\\n",
    "               'belgian_witbier': 'https://www.beeradvocate.com/lists/style/48/',\\\n",
    "               'berliner_weisse': 'https://www.beeradvocate.com/lists/style/87/',\\\n",
    "               'ger_dunkel': 'https://www.beeradvocate.com/lists/style/91/',\\\n",
    "               'ger_hefe': 'https://www.beeradvocate.com/lists/style/89/',\\\n",
    "               'ger_kristal': 'https://www.beeradvocate.com/lists/style/90/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilsner_palelagers = {'am_adj_lager': 'https://www.beeradvocate.com/lists/style/38/',\\\n",
    "                      'am_imp_pils': 'https://www.beeradvocate.com/lists/style/164/',\\\n",
    "                      'am_lager': 'https://www.beeradvocate.com/lists/style/155/',\\\n",
    "                      'am_light_lager': 'https://www.beeradvocate.com/lists/style/39/',\\\n",
    "                      'am_malt_liq': 'https://www.beeradvocate.com/lists/style/42/',\\\n",
    "                      'bohemian_pils': 'https://www.beeradvocate.com/lists/style/40/',\\\n",
    "                      'eur_exp_dort': 'https://www.beeradvocate.com/lists/style/20/',\\\n",
    "                      'eur_pale_lager': 'https://www.beeradvocate.com/lists/style/37/',\\\n",
    "                      'eur_str_lager': 'https://www.beeradvocate.com/lists/style/43/',\\\n",
    "                      'ger_helles': 'https://www.beeradvocate.com/lists/style/21/',\\\n",
    "                      'ger_kell_zwick': 'https://www.beeradvocate.com/lists/style/131/',\\\n",
    "                      'ger_pils': 'https://www.beeradvocate.com/lists/style/41/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_pale_ale = { 'am_ipa': 'https://www.beeradvocate.com/lists/style/116/',\\\n",
    "                    'ne_ipa': 'https://www.beeradvocate.com/lists/style/189/',\\\n",
    "                    'imp_ipa': 'https://www.beeradvocate.com/lists/style/140/',\\\n",
    "                    'am_brut_ipa': 'https://www.beeradvocate.com/lists/style/199/',\\\n",
    "                    'bel_ipa': 'https://www.beeradvocate.com/lists/style/174/',\\\n",
    "                    'eng_ipa': 'https://www.beeradvocate.com/lists/style/150/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pale_ale = {'am_amber': 'https://www.beeradvocate.com/lists/style/128/',\\\n",
    "           'am_blonde': 'https://www.beeradvocate.com/lists/style/99/',\\\n",
    "           'apa': 'https://www.beeradvocate.com/lists/style/97/',\\\n",
    "           'bel_blonde': 'https://www.beeradvocate.com/lists/style/190/',\\\n",
    "           'bel_pale': 'https://www.beeradvocate.com/lists/style/54/',\\\n",
    "           'bel_saison': 'https://www.beeradvocate.com/lists/style/129/',\\\n",
    "           'eng_bit': 'https://www.beeradvocate.com/lists/style/98/',\\\n",
    "           'esb': 'https://www.beeradvocate.com/lists/style/66/',\\\n",
    "           'eng_pa': 'https://www.beeradvocate.com/lists/style/154/',\\\n",
    "           'eng_pma': 'https://www.beeradvocate.com/lists/style/76/',\\\n",
    "           'fren_bdg': 'https://www.beeradvocate.com/lists/style/127/',\\\n",
    "           'ger_kolsch': 'https://www.beeradvocate.com/lists/style/85/',\\\n",
    "           'irish_red': 'https://www.beeradvocate.com/lists/style/161/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_ale = {'am_brown': 'https://www.beeradvocate.com/lists/style/73/',\\\n",
    "            'eng_brown': 'https://www.beeradvocate.com/lists/style/74/',\\\n",
    "            'eng_dma': 'https://www.beeradvocate.com/lists/style/75/',\\\n",
    "            'ger_alt': 'https://www.beeradvocate.com/lists/style/86/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porters = {'am_imp_porter': 'https://www.beeradvocate.com/lists/style/192/',\\\n",
    "          'am_porter': 'https://www.beeradvocate.com/lists/style/159/',\\\n",
    "          'baltic_porter': 'https://www.beeradvocate.com/lists/style/80/',\\\n",
    "          'eng_porter': 'https://www.beeradvocate.com/lists/style/101/',\\\n",
    "          'rob_porter': 'https://www.beeradvocate.com/lists/style/193/',\\\n",
    "          'smoke_porter': 'https://www.beeradvocate.com/lists/style/194/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stouts = {'am_imp_stout': 'https://www.beeradvocate.com/lists/style/157/',\\\n",
    "         'am_stout': 'https://www.beeradvocate.com/lists/style/158/',\\\n",
    "         'eng_oat_stout': 'https://www.beeradvocate.com/lists/style/69/',\\\n",
    "         'eng_stout': 'https://www.beeradvocate.com/lists/style/13/',\\\n",
    "         'eng_swt_stout': 'https://www.beeradvocate.com/lists/style/82/',\\\n",
    "         'foreign_stout': 'https://www.beeradvocate.com/lists/style/95/',\\\n",
    "         'irish_stout': 'https://www.beeradvocate.com/lists/style/162/',\\\n",
    "         'rus_imp_stout': 'https://www.beeradvocate.com/lists/style/84/'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2 - Scrape every beer link\n",
    "\n",
    "After getting the link for each unqiue beer, the following section will scrape the following information for each beer:\n",
    "\n",
    "beer name  \n",
    "brewery name  \n",
    "beer subcategory  \n",
    "overall rating  \n",
    "number of ratings  \n",
    "number of reviews  \n",
    "alcohol percentage (ABV)\n",
    "\n",
    "Data will be inserted into MongoDB with each iteration of a unique beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def access_url(beer_type):\n",
    "    \"\"\" access url and retrieve bs4 lxml object\n",
    "        input: url \n",
    "        output: bs4 lxml object\n",
    "    \"\"\"\n",
    " \n",
    "    new_url = beer_type\n",
    "    new_response = requests.get(new_url)\n",
    "    new_page = new_response.text\n",
    "    new_soup = BeautifulSoup(new_page, \"lxml\")\n",
    "    return new_soup\n",
    "\n",
    "\n",
    "def get_beer_info(new_soup):\n",
    "    \"\"\" retrieve name of beer, name of brewery\n",
    "        input: bs4 lxml object\n",
    "        output: 2 strings\n",
    "    \"\"\"  \n",
    "    name = new_soup.findAll(class_='titleBar')\n",
    "    name = name[0].text.replace('\\n','').split('|')\n",
    "    beer_name = name[0]\n",
    "    brewery_name = name[1]\n",
    "    return beer_name, brewery_name\n",
    "\n",
    "\n",
    "def get_rating(new_soup):\n",
    "    \"\"\" retrieve rating of beer\n",
    "        input: bs4 lxml object\n",
    "        output: string\n",
    "    \"\"\"   \n",
    "    ba_score = new_soup.findAll(class_='ba-ravg')\n",
    "    rating = ba_score[0].text\n",
    "    return rating\n",
    "\n",
    "\n",
    "def get_num_rating(new_soup):\n",
    "    \"\"\"retrieve no. of ratings\"\"\"   \n",
    "    num_ratings = new_soup.findAll(class_='ba-ratings')\n",
    "    num_ratings = num_ratings[0].text\n",
    "    return num_ratings\n",
    "\n",
    "\n",
    "def get_num_reviews(new_soup):\n",
    "    \"\"\" retrieve no. of reviews\n",
    "        input: bs4 lxml object\n",
    "        output: string\n",
    "    \"\"\"   \n",
    "    num_reviews = new_soup.findAll(class_='ba-reviews')\n",
    "    num_reviews = num_reviews[0].text\n",
    "    return num_reviews \n",
    "\n",
    "\n",
    "def get_abv(new_soup):\n",
    "    \"\"\" retrieve abv\n",
    "        input: bs4 lxml object\n",
    "        output: string\n",
    "    \"\"\"\n",
    "    letters = 'abcdefghijklmnopqrstuwvxyz'\n",
    "    abv_info = new_soup.findAll('div', {'id':'info_box'})\n",
    "    for item in abv_info:\n",
    "        ary = item.text.split('\\n')\n",
    "        for i in ary:\n",
    "            if 'Alcohol by volume' in i:\n",
    "                abv_string = i\n",
    "                abv_ = abv_string.split(' ')[-1]\n",
    "                chars = list(abv_)\n",
    "                if chars[-2] not in letters:\n",
    "                    abv = round(float(abv_.strip('%')),2)\n",
    "                    return abv\n",
    "                else:\n",
    "                    return 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(beer_dict):\n",
    "\n",
    "    \"\"\"\n",
    "    function to scrape key info and append to csv\n",
    "\n",
    "    input - dictionary of beer list(s), where keys = beer sub category, values = list of links\n",
    "\n",
    "    output - list of stats appended to a mongodb database:\n",
    "             name of sub-category, beer name, brewery,\n",
    "             rating, no. rating, no reviews,  abv\n",
    "\n",
    "    \"\"\" \n",
    "    compiled_list =[]\n",
    "    \n",
    "    dict_keys = list(beer_dict.keys())\n",
    "    for i in dict_keys:\n",
    "        list_ = beer_dict[i]  # list of beers from dict_key \"i\"\n",
    "        new_list = [x + '0' for x in list_]  # add 0 to end of website link to get to first page\n",
    "        # loop through each link in new_list\n",
    "        for link in new_list:\n",
    "            url = access_url(link)\n",
    "            beer_name, brewery_name = get_beer_info(url)\n",
    "            rating = get_rating(url)\n",
    "            num_ratings = get_num_rating(url)\n",
    "            num_reviews = get_num_reviews(url)\n",
    "            alc = get_abv(url)\n",
    "            # get name of dictionary list to represent which category of beer\n",
    "            beer_sub_cat = i \n",
    "            beerlist = [beer_sub_cat,beer_name, brewery_name, rating, num_ratings, num_reviews, alc]\n",
    "            \n",
    "            print(beerlist)\n",
    "            compiled_list.append(beerlist)\n",
    "            \n",
    "            # insert data into mongoDB\n",
    "            beer_dict_db = {}\n",
    "            beer_dict_db['sub_cat'] = beer_sub_cat\n",
    "            beer_dict_db['beer_name'] = beer_name\n",
    "            beer_dict_db['brewery_name'] = brewery_name\n",
    "            beer_dict_db['rating'] = rating\n",
    "            beer_dict_db['num_ratings'] = num_ratings\n",
    "            beer_dict_db['num_reviews'] = num_reviews\n",
    "            beer_dict_db['alc'] = alc\n",
    "            client.beer_db.beer_collection.insert_one(beer_dict_db)\n",
    "            print('mongo insert complete')\n",
    "            \n",
    "    return compiled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Mongo to recieve data\n",
    "\n",
    "Note: all scraped data is stored in a Mongo database hosted on AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"localhost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create collection\n",
    "beer_collection = client.beer_db['beer_collection'] \n",
    "\n",
    "# beer_db was previously created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two commands were used to get all of the scraped data from each of the 7 beer subcategory dictionaries (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_name_list = compile_list(beer_dictionary)\n",
    "beer_name_db = get_info(beer_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example - for the wheat beer subcategory\n",
    "all_wheat_list = compile_list(wheat_beers)\n",
    "all_wheat_db = get_info(all_wheat_list)\n",
    "\n",
    "# wheat_beers is the dictionary defined above\n",
    "# compile_list, get_info are functions defined above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 - Scrape User Ratings\n",
    "\n",
    "Scrape all user review(rating) for each unique beer. This is different than Part 2. Part 2 extracts all relevant info on the first page of each unique beer. Part 3 iterates through each page to extract all user - rating pairings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews_assorted = client.beer_db['user_reviews_assorted'] # run once only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rate_count(new_soup):\n",
    "    \"\"\" \n",
    "    find number of ratings to determine number of iterations \n",
    "    input: bs4 object\n",
    "    output: integer\n",
    "    \"\"\"\n",
    "    \n",
    "    rating = new_soup.findAll(class_='ba-ratings')\n",
    "    rc = rating[0].text\n",
    "    rating_count = int(rc.replace(',',''))\n",
    "    # divide rating by 25 and round down to get number of iterations\n",
    "    ct = rating_count//25 \n",
    "    # return last page (intger)\n",
    "    page_end_ = ct*25\n",
    "    return page_end_\n",
    "\n",
    "\n",
    "def get_rating_reviewer(soup_):\n",
    "    \"\"\"\n",
    "    retreive all of the reviewer - rating pairs on each webpage\n",
    "    \n",
    "    Input: bs4 object \n",
    "    Output: list of 25 username, rating tuple pairs\n",
    "    \"\"\"\n",
    "\n",
    "    info_ = soup_.findAll(class_='BAscore_norm')\n",
    "    info_user = soup_.findAll(class_='username')\n",
    "    tuple_list = []\n",
    "    user_list = []\n",
    "    rating_list = []\n",
    "    \n",
    "    # get list of users\n",
    "    for i in range(len(info_user)):\n",
    "        if info_user[i].text is not '':\n",
    "            user_list.append(info_user[i].text)\n",
    "    user_list = user_list[1:]\n",
    "    \n",
    "    # get list of ratings\n",
    "    for i in range(len(info_)):\n",
    "        uni_rating = float(info_[i].text)\n",
    "        uni_rating2 = format(uni_rating, '.2f')\n",
    "        rating_list.append(uni_rating2)\n",
    "    \n",
    "    # append users and ratings as tuple pair\n",
    "    for i in range(len(user_list)):\n",
    "        t = user_list[i], rating_list[i]\n",
    "        tuple_list.append(t)\n",
    "\n",
    "    return tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_reviewers(beer_dict):\n",
    "    '''\n",
    "    Get ratings and reviewers\n",
    "    \n",
    "    Input = dictionary\n",
    "    Output = dictionary \n",
    "    \n",
    "    Results inserted into Mongodb\n",
    "    \n",
    "    '''\n",
    "    # initiate master dictionary \n",
    "    user_reviews_beer_dict={}\n",
    "    beer_tuple_list=[] \n",
    "    \n",
    "    dict_keys = list(beer_dict.keys())\n",
    "\n",
    "    for i in dict_keys:\n",
    "        list_ = beer_dict[i]  # list of beers from dict_key \"i\"\n",
    "        for link in list_:\n",
    "            letters = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "            start = 0\n",
    "            page_end = 2 #integer representing the last page, 2 is placeholder  \n",
    "            count = 0\n",
    "\n",
    "            while count <= page_end:\n",
    "                if count ==0:\n",
    "                    time.sleep(1)\n",
    "                    first_page = link+'0'\n",
    "                    url = access_url(first_page)\n",
    "\n",
    "                    # find number of ratings to determine number of iterations (turn this into function)\n",
    "                    page_end = find_rate_count(url) \n",
    "\n",
    "                    # get name of beer\n",
    "                    beer_name_, brewery_name = get_beer_info(url)\n",
    "\n",
    "                    beer_name = beer_name_.replace('.','').replace('$','')\n",
    "                    \n",
    "                    # get individual rating, get reviewer name\n",
    "                    tup = get_rating_reviewer(url)\n",
    "                    \n",
    "                    # initiate new dict key-value\n",
    "                    user_reviews_beer_dict[beer_name]=[]\n",
    "                    # append to dict\n",
    "                    for item in tup:\n",
    "                        user_reviews_beer_dict[beer_name].append(item)                    \n",
    "                    count +=25\n",
    "\n",
    "                else:\n",
    "                    other_pages = link + str(count)\n",
    "                    url = access_url(other_pages)\n",
    "\n",
    "                    # get individual rating, get reviewer name\n",
    "                    tup = get_rating_reviewer(url)\n",
    "                    \n",
    "                    # append to dict\n",
    "                    for item in tup:\n",
    "                        user_reviews_beer_dict[beer_name].append(item)\n",
    "                    count +=25\n",
    "    \n",
    "    \n",
    "    # extract data and insert into MongoDB\n",
    "    all_reviews = []\n",
    "\n",
    "    for key in list(user_reviews_beer_dict.keys()):\n",
    "        d = {}\n",
    "        d['Beer'] = key\n",
    "        d['UserReviews'] = user_reviews_beer_dict[key]\n",
    "        all_reviews.append(d)\n",
    "\n",
    "    \n",
    "    for item in all_reviews:\n",
    "        client.beer_db.user_reviews_assorted.insert_one(item)\n",
    "    \n",
    "    # return dictionary object\n",
    "    return user_reviews_beer_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code for each beer subcategory to scrape all user-review pairing and insert into MongoDB\n",
    "\n",
    "beer_name_list = compile_list(beer_dictionary)  \n",
    "beer_name_db = rating_reviewers(beer_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "all_wheat_list = compile_list(wheat_beers)\n",
    "\n",
    "all_wheat_user_reviews = rating_reviewers(all_wheat_list)\n",
    "\n",
    "# repeat this for the other 6 subcategories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
